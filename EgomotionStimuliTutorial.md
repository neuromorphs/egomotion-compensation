# ðŸŽ¨ PsychoPy: Create Your First Stimulus

This tutorial helps you use PsychoPy's **Coder** to generate a simple visual stimulus, animate it, and respond to keyboard input. It walks through setting up a window, creating stimuli (e.g., gratings and fixation points), and animating them with loops.

For more details, check the full [tutorial](https://www.psychopy.org/coder/tutorial1.html). ðŸŽ‰


# ðŸ¤– v2e Tutorial

This colab script is to demonstrate the use of v2e - tutorial [HERE](https://colab.research.google.com/drive/1czx-GJnx-UkhFVBbfoACLVZs8cYlcr_M?usp=sharing#scrollTo=28paqWVLhe0p)

For more technical details, please find in our paper: v2e: From Video Frames to Realistic DVS Events [here](https://arxiv.org/abs/2006.07722)

Our YouTube Tutorial: [here](https://www.youtube.com/watch?v=THJqRC_q2kY&t)

Colab provides free GPU resources, you can also use this script as a tool for converting videos to events.

# Link to the Stimuli

You can find the egomotion stimuli [here](https://campuscvut-my.sharepoint.com/:f:/r/personal/dangegiu_cvut_cz/Documents/egomotionstimuli?csf=1&web=1&e=7dDRzB).

- egomotion
- egomotion+object moving
- only object moving

[HERE](https://github.com/neuromorphs/attention-egomotion/blob/robot-attention/ReadEvents.py) the code to read the events (events.h5) - you find the events in data = list(f[a_group_key])
Please, do remember to include the events.h5 file in your repo !!!!!!
